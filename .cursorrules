# RegReportRAG - AI Assistant Rules

# Instructions

During your interaction with the user, if you find anything reusable in this project (e.g., version of a library, model name), especially about a fix to a mistake you made or a correction you received, you should take note in the `Lessons` section in the `.cursorrules` file so you will not make the same mistake again.

You should also use the `.cursorrules` file as a Scratchpad to organize your thoughts. Especially when you receive a new task, you should first review the content of the Scratchpad, clear old different task if necessary, first explain the task, and plan the steps you need to take to complete the task. You can use todo markers to indicate the progress, e.g.
[X] Task 1
[ ] Task 2

Also update the progress of the task in the Scratchpad when you finish a subtask.
Especially when you finished a milestone, it will help to improve your depth of task accomplishment to use the Scratchpad to reflect and plan.
The goal is to help you maintain a big picture as well as the progress of the task. Always refer to the Scratchpad when you plan the next step.

# Project Overview

This project is a **Regulatory Report RAG (Retrieval-Augmented Generation) System** that processes regulatory documents, extracts relevant information, and generates compliance reports using AI-powered document analysis.

## Core Features
* **Document Processing**: Automated regulatory document ingestion and processing
* **RAG Integration**: Retrieval-augmented generation for accurate report creation
* **Compliance Checking**: Automated compliance validation and reporting
* **Vector Search**: Semantic search capabilities for regulatory content
* **API Integration**: RESTful API for document processing and report generation
* **Frontend Interface**: React-based user interface for document management

## Technical Architecture
* **Backend**: FastAPI (Python)
* **Frontend**: React with TypeScript
* **Database**: PostgreSQL (with pgvector) for vector storage and semantic search
* **AI/ML**: RAG system with document embeddings
* **Document Processing**: PDF and text document parsing
* **Vector Database**: PostgreSQL (pgvector) for semantic search

# Project-Specific Rules

1. **File and Directory Structure:**
```
RegReportRAG/
├── backend/
│   ├── app/
│   │   ├── main.py              # FastAPI application entry point
│   │   ├── models/              # Database models and schemas
│   │   ├── services/            # Business logic and services
│   │   └── utils/               # Utility functions
│   ├── data/                    # Data storage (ChromaDB)
│   ├── logs/                    # Application logs
│   └── requirements.txt         # Python dependencies
├── frontend/
│   ├── src/
│   │   ├── components/          # React components
│   │   ├── services/            # API service layer
│   │   └── App.js               # Main React application
│   ├── public/                  # Static assets
│   └── package.json             # Node.js dependencies
├── docs/                        # Documentation
├── data/                        # Shared data directory
├── logs/                        # Application logs
└── docker-compose.yml           # Docker configuration
```

2. **API Keys and Environment Variables:**
* Store API keys in `.env` files (use `.env.example` as template)
* Use `python-dotenv` for environment variable management
* Example `.env.example`:
```
OPENAI_API_KEY=
POSTGRES_DB=
POSTGRES_USER=
POSTGRES_PASSWORD=
```
**CRITICAL: NEVER COMMIT .ENV FILES TO GIT**

3. **Document Processing:**
* Support PDF and text document formats
* Implement proper document validation
* Handle large file uploads efficiently
* Extract text content for RAG processing
* Store document metadata in PostgreSQL

4. **RAG System Implementation:**
* Use PostgreSQL (with pgvector) for vector storage
* Implement document chunking strategies
* Create semantic embeddings for document sections
* Build retrieval mechanisms for relevant content
* Generate context-aware responses

5. **Database Management:**
* Use PostgreSQL for structured data and vector embeddings
* Implement proper database migrations
* Handle database connections efficiently
* Backup and recovery procedures

6. **API Design:**
* RESTful API endpoints
* Proper HTTP status codes
* Request/response validation with Pydantic
* Error handling and logging
* API documentation with OpenAPI/Swagger

7. **Frontend Development:**
* React with TypeScript
* Component-based architecture
* Responsive design principles
* State management best practices
* API integration patterns

8. **Error Handling:**
* Comprehensive error handling at all layers
* Informative error messages
* Proper logging with different levels
* Graceful degradation
* User-friendly error displays

9. **Testing:**
* Unit tests for all components
* Integration tests for API endpoints
* Frontend component testing
* End-to-end testing scenarios
* Mock external dependencies

10. **Security:**
* Input validation and sanitization
* SQL injection prevention
* XSS protection
* CORS configuration
* Authentication and authorization

# Tools and Technologies

* **Backend**: Python, FastAPI, Pydantic, SQLAlchemy
* **Frontend**: React, TypeScript, Tailwind CSS
* **Database**: PostgreSQL
* **Document Processing**: PyPDF2, python-docx
* **AI/ML**: OpenAI API, sentence-transformers
* **Testing**: pytest, pytest-asyncio, React Testing Library
* **Documentation**: Markdown, OpenAPI/Swagger
* **Deployment**: Docker, Docker Compose

# Communication Guidelines

1. **User Profile:**
   - Target Audience: Developers and compliance professionals
   - Technical Level: Intermediate to advanced
   - Goals: Build a robust regulatory document processing system
   - Pain Points: Complex document processing, compliance requirements

2. **Communication Style:**
   - Use clear, technical language
   - Provide detailed explanations for complex concepts
   - Include code examples and documentation
   - Explain architectural decisions
   - Offer best practices and recommendations

# Code Generation Rules

1. **Backend Code:**
   - Follow FastAPI best practices
   - Use type hints throughout
   - Implement proper error handling
   - Add comprehensive logging
   - Use Pydantic for data validation

2. **Frontend Code:**
   - Follow React best practices
   - Use TypeScript for type safety
   - Implement responsive design
   - Handle loading and error states
   - Use proper state management

3. **Database Code:**
   - Use SQLAlchemy ORM patterns
   - Implement proper migrations
   - Handle database transactions
   - Optimize queries for performance
   - Use connection pooling

# Security Guidelines

1. **API Security:**
   - Validate all inputs
   - Implement rate limiting
   - Use HTTPS in production
   - Handle sensitive data properly
   - Implement proper authentication

2. **Data Security:**
   - Encrypt sensitive data
   - Implement proper access controls
   - Regular security audits
   - Backup and recovery procedures
   - Compliance with data protection regulations

# Performance Guidelines

1. **Backend Performance:**
   - Optimize database queries
   - Implement caching strategies
   - Use async/await patterns
   - Monitor resource usage
   - Profile application performance

2. **Frontend Performance:**
   - Optimize bundle size
   - Implement lazy loading
   - Use efficient rendering patterns
   - Minimize API calls
   - Optimize images and assets

# Testing Guidelines

1. **Test Coverage:**
   - Unit tests for all business logic
   - Integration tests for API endpoints
   - Frontend component testing
   - End-to-end testing scenarios
   - Performance testing

2. **Test Quality:**
   - Meaningful test names
   - Clear test descriptions
   - Proper test isolation
   - Mock external dependencies
   - Test edge cases and error conditions

# Documentation Requirements

1. **Code Documentation:**
   - Comprehensive docstrings
   - API documentation
   - Architecture diagrams
   - Setup and deployment guides
   - Troubleshooting documentation

2. **User Documentation:**
   - User guides and tutorials
   - API reference documentation
   - Configuration guides
   - Best practices documentation
   - FAQ and troubleshooting

# Lessons Learned

* **API Keys**: Always use environment variables for API keys. Never commit API keys to version control.
* **Git Security**: When API keys are accidentally committed to git history, use git filter-repo to completely remove sensitive data from GitHub. Always enhance .gitignore to prevent future exposures.
* **Emergency API Key Procedures**: If API keys are exposed in git history: 1) Immediately revoke the exposed key, 2) Create new API key, 3) Use git filter-repo to completely rewrite git history, 4) Force push to replace remote history, 5) Clear local reflog and run aggressive garbage collection, 6) Enhance .gitignore with comprehensive exclusions.
* **Document Processing**: Implement proper document validation and error handling for various file formats.
* **Vector Database**: Use PostgreSQL efficiently with proper chunking and embedding strategies.
* **RAG Implementation**: Ensure proper context retrieval and response generation for accurate results.
* **Database Management**: Implement proper migrations and backup procedures for PostgreSQL.
* **Frontend State Management**: Handle complex state updates and API interactions properly.
* **Error Handling**: Implement comprehensive error handling at all layers with proper user feedback.
* **Testing**: Write thorough tests for document processing, RAG functionality, and API endpoints.
* **Performance**: Optimize document processing and vector search for large document collections.
* **Security**: Follow security best practices for handling sensitive regulatory documents.
* **Technical Documentation**: When explaining complex systems like RAG, provide both high-level overviews and detailed technical specifications. Use interactive elements, visual diagrams, and real-world examples to make technical concepts accessible. Break down complex processes into digestible steps with expandable sections for those who want deeper understanding.
* **Multi-Model AI Integration**: Successfully implemented alternative AI provider support with Google Gemini for both embeddings and LLM processing. Key considerations: 1) Use task-specific embedding types (retrieval_document vs retrieval_query), 2) Configure appropriate safety settings for LLM models, 3) Handle API rate limits and quotas, 4) Maintain backward compatibility with existing PostgreSQL vector storage, 5) Implement comprehensive testing for both embedding generation and RAG functionality.
* **Google Generative AI Import Fix**: The google-generativeai library (version 0.3.2) does not support direct import of embed function. Use `import google.generativeai as genai` and call `genai.embed_content()` instead of `from google.generativeai import embed`. The correct API structure is: `genai.embed_content(model=model, content=text, task_type="retrieval_document")` for document embeddings and `task_type="retrieval_query"` for query embeddings.
* **Multi-Model Vector Database Support**: When using different AI providers (OpenAI vs Gemini), create separate database tables for different embedding dimensions. OpenAI embeddings are 1536 dimensions while Gemini embeddings are 768 dimensions. Solution: Create provider-specific database models (e.g., `document_chunks` for OpenAI, `gemini_document_chunks` for Gemini) to avoid dimension mismatch errors. This allows both embedding types to coexist in the same PostgreSQL database with pgvector extension.

# Scratchpad

Current Task: [X] Gemini CLI Testing & Vector Dimension Fix - COMPLETED ✅
Project Status: Multi-model AI integration complete with Google Gemini support and full CLI testing!

## Task: Standalone PDF Loader Implementation ✅

### Overview
Successfully implemented a comprehensive standalone PDF loader system that allows processing PDFs to vector database without running the full FastAPI application.

### Implementation Details
- **load_pdfs_to_vector_db.py**: Main standalone script for PDF processing
- **test_pdf_loader.py**: Comprehensive test suite with sample PDF generation
- **README_PDF_LOADER.md**: Detailed documentation and usage guide
- **Smart Features**: Duplicate detection, status monitoring, flexible input options
- **Command Line Interface**: Multiple usage modes (default, custom files, reload, status)
- **Comprehensive Logging**: Detailed logs for debugging and monitoring
- **Error Handling**: Robust error handling and recovery mechanisms

### Key Features Implemented
1. **Standalone Processing**: Load PDFs without starting web server
2. **Smart Duplicate Detection**: Skip already processed files (MD5 hash-based)
3. **Status Monitoring**: Check document status and statistics
4. **Flexible File Input**: Process default PDFs or specify custom files
5. **Reload Capability**: Clear and reprocess all documents
6. **Test Suite**: Automated testing with sample PDF generation
7. **Production Ready**: Full logging, error handling, and documentation

### Usage Examples
```bash
# Load default PDFs
python load_pdfs_to_vector_db.py

# Load custom files
python load_pdfs_to_vector_db.py --pdf-files file1.pdf file2.pdf

# Check status
python load_pdfs_to_vector_db.py --status

# Reload all documents
python load_pdfs_to_vector_db.py --reload

# Run test suite
python test_pdf_loader.py
```

### Technical Implementation
- **PDF Processing**: PyPDF2 for text extraction with page tracking
- **Text Chunking**: 1000 tokens with 200 overlap, semantic splitting
- **Vector Embeddings**: OpenAI text-embedding-3-small (1536 dimensions)
- **Database Storage**: PostgreSQL with pgvector extension
- **Change Detection**: MD5 hash comparison for efficient updates
- **Chunk Classification**: Automatic content type detection

### Files Created
- `backend/load_pdfs_to_vector_db.py` - Main loader script
- `backend/test_pdf_loader.py` - Test suite with PDF generation
- `backend/README_PDF_LOADER.md` - Comprehensive documentation
- Updated `backend/requirements.txt` - Added reportlab dependency

### Repository Status
- **Remote URL**: https://github.com/dhamosankaran/RegReport.git
- **Branch**: main
- **Status**: All PDF loader files successfully pushed
- **Commit**: b96d5ac - Standalone PDF loader implementation

## Task: Gemini Vector Service Implementation ✅

### Overview
Successfully implemented a comprehensive standalone vector service using Google Gemini for embeddings and Gemini Flash for LLM processing, providing an alternative to the OpenAI-based system.

### Implementation Details
- **vector_service_gemini.py**: Main Gemini-based vector service implementation
- **test_gemini_service.py**: Comprehensive test suite with detailed reporting
- **README_GEMINI_VECTOR_SERVICE.md**: Complete documentation and usage guide
- **requirements.txt**: Updated with Google Generative AI dependency
- **Multi-Model Support**: Seamless integration with existing PostgreSQL vector storage

### Key Features Implemented
1. **Gemini Embeddings**: text-embedding-004 model for high-quality embeddings
2. **Gemini Flash LLM**: gemini-1.5-flash for fast, intelligent responses
3. **Standalone Operation**: Works independently from main FastAPI application
4. **RAG Integration**: Complete retrieval-augmented generation pipeline
5. **Comprehensive Testing**: Full test suite with 4 test categories
6. **Production Ready**: Error handling, logging, and monitoring
7. **Backward Compatibility**: Uses same PostgreSQL database structure

### Usage Examples
```bash
# Run comprehensive test suite
python test_gemini_service.py

# Use standalone service
python vector_service_gemini.py

# Import in code
from vector_service_gemini import GeminiVectorService
```

### Technical Implementation
- **AI Provider**: Google Gemini API with task-specific embedding types
- **Safety Settings**: Configured for regulatory document processing
- **Vector Database**: PostgreSQL with pgvector (same as OpenAI implementation)
- **Testing Framework**: Comprehensive test suite with detailed reporting
- **Documentation**: Complete API reference and troubleshooting guide

### Files Created
- `backend/vector_service_gemini.py` - Main Gemini service implementation
- `backend/test_gemini_service.py` - Comprehensive test suite
- `backend/README_GEMINI_VECTOR_SERVICE.md` - Complete documentation
- Updated `backend/requirements.txt` - Added google-generativeai dependency

### Multi-Model Capabilities
- **Alternative AI Provider**: Google Gemini as alternative to OpenAI
- **Embedding Models**: text-embedding-004 (768 dimensions)
- **LLM Models**: gemini-1.5-flash for fast responses
- **API Management**: Proper quota and rate limit handling
- **Cross-Platform**: Works with same database as OpenAI implementation

### CLI Testing Completion ✅
- **Vector Dimension Fix**: Created separate `gemini_document_chunks` table for 768D embeddings
- **Environment Loading**: Fixed .env file loading in CLI for proper API key access
- **Full Pipeline Testing**: Successfully tested document loading, RAG queries, and semantic search
- **Test Document Creation**: Generated regulatory PDFs (Compliance Guide, Risk Management Policy, Data Governance Manual)
- **CLI Commands Working**: All CLI commands functional - load, query, search, status, clear, interactive
- **Database Coexistence**: Gemini (768D) and OpenAI (1536D) embeddings work in same PostgreSQL database

# Progress Tracking
- [X] Project initialization
- [X] Basic setup complete
- [X] Core features implemented
- [X] Advanced features completed
- [X] E2E Testing Suite Implementation
- [X] RAG Vector Embedding Flow Documentation
- [X] Documentation finished
- [X] Git repository push completed
- [X] Repository migration to RegReport completed
- [X] Backend models fixed and pushed
- [X] Technical Deep Dive UI section added
- [X] Standalone PDF Loader Implementation completed
- [X] Gemini Vector Service Implementation completed  
- [X] Ready for deployment

# Next Steps
1. ✅ Complete E2E testing suite implementation
2. ✅ Set up CI/CD pipeline with testing
3. ✅ Create comprehensive test documentation
4. ✅ Document RAG vector embedding flow
5. ✅ Push codebase to GitHub repository
6. ✅ Migrate to RegReport repository
7. ✅ Fix missing backend models
8. ✅ Add Technical Deep Dive documentation
9. ✅ Create standalone PDF loader tools
10. ✅ Implement Gemini Vector Service for multi-model AI support
11. Ready for production deployment and team collaboration

# Notes
- Successfully migrated complete RegReportRAG system to RegReport repository
- All 52 files and comprehensive documentation now available in new repository
- Remote origin changed from RAGRegReport to RegReport
- Main branch created and pushed with complete codebase
- **FIXED**: Added missing backend/app/models/ directory that was ignored by .gitignore
- Added exception !backend/app/models/ to .gitignore to allow backend models
- Successfully pushed database.py, schemas.py, and __init__.py to repository
- Enhanced UI with Technical Deep Dive section including document processing pipeline and E2E methods
- **NEW**: Added standalone PDF loader system with comprehensive testing and documentation
- Created production-ready tools for PDF processing without full application startup
- **NEW**: Implemented Gemini Vector Service for multi-model AI support with Google Gemini
- Added comprehensive Gemini-based RAG system with text-embedding-004 and gemini-1.5-flash
- Repository is now complete with all essential backend models and standalone tools
- Ready for collaborative development and deployment with enhanced PDF processing and multi-model AI capabilities 